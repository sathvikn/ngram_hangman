{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will make a character-based n-gram model from a large sample of text and use it to estimate the probability another sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pdb # for debugging\n",
    "import numpy as np # for vector operations and math\n",
    "import sys\n",
    "def subsequences(l, n):\n",
    "    return(zip(*(l[i:] for i in range(n))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,), (1,), (2,), (3,), (4,), (5,), (6,), (7,), (8,)]\n",
      "[(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8)]\n"
     ]
    }
   ],
   "source": [
    "#example use of subsequences\n",
    "print(subsequences(range(9),1))\n",
    "print(subsequences(range(9),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by reading the large sample of text in `en_train.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# VISIBLE\n",
    "# initialize storage for the model\n",
    "ngram = {}\n",
    "for i in range(1,4):\n",
    "    ngram[i] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#VISIBLE\n",
    "with open('en_train_ascii.txt','r') as f:\n",
    "    for x in f:\n",
    "        words = x.replace('\\n','').split(' ')\n",
    "        characters = [x.lower() for x in list(x.replace('\\n',''))]        \n",
    "        \n",
    "        #NOT VISIBLE: SOLUTION FOR POPULATING THE DATASET\n",
    "        for i in range(1,4):                        \n",
    "            for char_sequence in subsequences(characters, i):                \n",
    "                if ''.join(char_sequence) in ngram[i]:\n",
    "                    ngram[i][''.join(char_sequence)] += 1\n",
    "                else:\n",
    "                    ngram[i][''.join(char_sequence)] = 1        \n",
    "\n",
    "                    \n",
    "ngram[0] = np.sum(ngram[1].values())                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0674187009782\n"
     ]
    }
   ],
   "source": [
    "print(float(ngram[3]['str']) / ngram[2]['st'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VISIBLE\n",
    "def getProbability(character, context, ngram):\n",
    "    '''get the conditional probability of the character given the context'''\n",
    "    model_order  = len(context) + 1\n",
    "    sequence = ''.join(context + [character])\n",
    "    numerator = ngram[model_order][sequence]\n",
    "    if model_order == 1:\n",
    "        denominator = ngram[0]\n",
    "    else:    \n",
    "        denominator = ngram[model_order-1][''.join(context)] \n",
    "    return(float(numerator) / float(denominator))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0943070810343\n",
      "0.177743743859\n"
     ]
    }
   ],
   "source": [
    "print(getProbability('e',[], ngram))\n",
    "print(getProbability('e',['p'], ngram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(n, context_length):\n",
    "    '''produce a string of length n, using the specified context length'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# probability of a held-out set?\n",
    "def computeProbTestSet(filename, order):\n",
    "    probs_store = [] \n",
    "    with open(filename,'r') as f:\n",
    "        for x in f:\n",
    "            words = x.replace('\\n','').split(' ')\n",
    "            characters = [x.lower() for x in list(x.replace('\\n',''))]        \n",
    "            sequences = subsequences(characters,order)\n",
    "            sentence_prob = []\n",
    "            for sequence in sequences:\n",
    "    #             print(sequence[2])\n",
    "    #             print(''.join(list(sequence[0:2])))\n",
    "    #             pdb.set_trace()\n",
    "                sentence_prob.append(np.log(getProbability(sequence[order-1], list(sequence)[0:order-1], ngram)))\n",
    "            probs_store.append(np.sum(sentence_prob))    \n",
    "    print(np.sum(probs_store))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9491285.0899819471"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log((1/float(27)))*2879780"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8025236.98228\n"
     ]
    }
   ],
   "source": [
    "computeProbTestSet('en_test_within_ascii.txt',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6364835.02565\n"
     ]
    }
   ],
   "source": [
    "computeProbTestSet('en_test_within_ascii.txt',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4885605.8259\n"
     ]
    }
   ],
   "source": [
    "computeProbTestSet('en_test_within_ascii.txt',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate a string per a context order\n",
    "# this data structure isn't great for this\n",
    "def generateString(charlength, ngram, order):    \n",
    "    output = []\n",
    "    for char_index in range(charlength):  \n",
    "        #print('New Letter')\n",
    "        #print(str(max(char_index-(order -1), 0))+' - ' +str(char_index))\n",
    "        preceding_context = output[max(0, char_index-(order -1)):char_index]\n",
    "        #print('preceding_context: ' + ''.join(preceding_context))\n",
    "        \n",
    "        cds = ngram[len(preceding_context)+1].keys()\n",
    "        #but not all of these are consistent with the preceding context\n",
    "        filtered_cds = [x for x in cds if list(x)[0:len(preceding_context)] == preceding_context]\n",
    "        #print(filtered_cds)\n",
    "        \n",
    "        filtered_counts = np.array([ngram[len(preceding_context)+1][x] for x in filtered_cds])\n",
    "        if len(preceding_context) == 0:\n",
    "            normalizer = float(ngram[0])\n",
    "        else:\n",
    "            normalizer = float(np.sum(filtered_counts))\n",
    "            \n",
    "        filtered_probs = filtered_counts / normalizer\n",
    "        #print(np.sum(filtered_probs))\n",
    "        \n",
    "        choice = list(np.random.choice(filtered_cds, p = filtered_probs))[-1]\n",
    "        #print('Choice: '+choice)\n",
    "        output.append(choice)\n",
    "        \n",
    "    return (''.join(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nhh t bbht  twn it o etwhrhraooka haui num e bi  tclstarhihasdm n elnaebjr o c oay  os ea hht d og o'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateString(100, ngram, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ofr at per terit hut y ig y haveresi e ft witavede ckndckwhingetieat ai mauser s wotheas thyoffellie'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateString(100, ngram, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vere hen oneall the throut las is nowright mpir ritump art wilive hill com sont ifflove you will ric'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateString(100, ngram, 3)\n",
    "#this should work fine without smoothing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
